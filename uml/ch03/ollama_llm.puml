@startuml ollama_llm_class
!include ../common/book-clean.puml


package "llm_agents_from_scratch.base.llm" <<Folder>> {
  abstract class BaseLLM {
    --
    +<<async>> complete(\n\tprompt: str\n): CompleteResult\n
    +<<async>> chat(\n\tinput: str,\n\tchat_history: list[ChatMessage],\n\ttools: list[BaseTool | AsyncBaseTool]\n): tuple[ChatMessage, ChatMessage]\n
    +<<async>> continue_chat_with_tool_results(\n\ttool_call_results: list[ToolCallResult],\n\tchat_history: list[ChatMessage]\n): tuple[list[ChatMessage], ChatMessage]\n
    +<<async>> structured_output<T>(\n\tprompt:str,\n\tmdl: type[T]\n): T
  }
}

package "llm_agents_from_scratch.llms" <<Folder>> {

  class OllamaLLM {
    +model: str
    -_client: ~ollama.AsyncClient
    --
    +<<constructor>> __init__(\n\tmodel:str,\n\thost: str | None\n):
  }
}

' Relations
BaseLLM <|-- OllamaLLM : " inherits"

@enduml
