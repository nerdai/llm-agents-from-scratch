{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60405002-e4c4-4ee2-8aae-53e704cdba1c",
   "metadata": {},
   "source": [
    "# Examples from Chapter 5 — MCP Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb4d8c3-8137-4fd3-bf37-c5359018538e",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "\n",
    "To ensure you have the required dependencies to run this notebook, you'll need to have our `llm-agents-from-scratch` framework installed on the running Jupyter kernel. To do this, you can launch this notebook with the following command while within the project's root directory:\n",
    "\n",
    "```sh\n",
    "uv run --with jupyter jupyter lab\n",
    "```\n",
    "\n",
    "Alternatively, if you just want to use the published version of `llm-agents-from-scratch` without local development, you can install it from PyPi by uncommenting the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd15ba8-e106-486e-afb5-8deef2dee2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to install `llm-agents-from-scratch` from PyPi\n",
    "# !pip install llm-agents-from-scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf43a249-cbd0-4e70-b8d0-3fd14b4b32ac",
   "metadata": {},
   "source": [
    "## Running an Ollama service\n",
    "\n",
    "To execute the code provided in this notebook, you’ll need to have Ollama installed on your local machine and have its LLM hosting service running. To download Ollama, follow the instructions found on this page: https://ollama.com/download. After downloading and installing Ollama, you can start a service by opening a terminal and running the command `ollama serve`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a94c6c-a08f-4850-8c15-dd68fb6ee4c4",
   "metadata": {},
   "source": [
    "## The Hailstone MCP server\n",
    "The examples in this notebook demonstrate how to use the framework's MCP integration using a toy MCP server that exposes the familiar Hailstone tool.\n",
    "\n",
    "**Important:** Run this notebook from within the project's root directory.\n",
    "\n",
    "The code for the MCP server is located at: https://github.com/nerdai/llm-agents-from-scratch/tree/main/extra/mcp-hailstone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f8ec9a-28e2-4e5e-942f-091e789ed14b",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6281fc2-5412-446c-8c80-3226eaeabe5a",
   "metadata": {},
   "source": [
    "### Example 1: Creating an `MCPToolProvider`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b1850b6-7b43-4f80-9b10-216ffb7a93d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_agents_from_scratch.tools.mcp import MCPToolProvider\n",
    "from mcp import StdioServerParameters\n",
    "from pathlib import Path\n",
    "\n",
    "server_path = Path.cwd().parent / \"extra/mcp-hailstone\"\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"uv\",\n",
    "    args=[\"run\", \"--with\", \"mcp\", \"mcp\", \"run\", \"main.py\"],\n",
    "    cwd=server_path,\n",
    ")\n",
    "provider = MCPToolProvider(\n",
    "    name=\"hailstone\",\n",
    "    stdio_params=server_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a895652-6d4a-4474-ba07-4e898d454cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llm_agents_from_scratch.tools.mcp.provider.MCPToolProvider at 0x7b2ea43e4440>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provider"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
