{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f543e077-3ac7-428c-96a0-71120e82e60a",
   "metadata": {},
   "source": [
    "# GoodNews MCP Example\n",
    "\n",
    "This notebook demonstrates how to connect an `LLMAgent` to a locally running\n",
    "stdio MCP server using the stdio transport introduced in Chapter 5. The MCP\n",
    "server used here is [`mcp-goodnews`](https://github.com/VectorInstitute/mcp-goodnews),\n",
    "developed by the author, which fetches and surfaces positive news articles via\n",
    "the [NewsAPI](https://newsapi.org/).\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- A NewsAPI API key stored in the environment variable `NEWS_API_KEY`\n",
    "- A Cohere API key stored in the environment variable `COHERE_API_KEY`\n",
    "- The `mcp-goodnews` server cloned and available locally\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "To ensure you have the required dependencies to run this notebook, you'll need to have our `llm-agents-from-scratch` framework installed on the running Jupyter kernel. To do this, you can launch this notebook with the following command while within the project's root directory:\n",
    "\n",
    "```sh\n",
    "# we need the notebook-utils and openai extras for this notebook\n",
    "uv sync --extra notebook-utils --extra openai\n",
    "\n",
    "# to launch the notebook\n",
    "uv run --with jupyter jupyter lab\n",
    "```\n",
    "\n",
    "Alternatively, if you just want to use the published version of `llm-agents-from-scratch` without local development, you can install it from PyPI by uncommenting the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a92de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to install `llm-agents-from-scratch` from PyPI\n",
    "# !pip install 'llm-agents-from-scratch[notebook-utils,openai]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3727773b",
   "metadata": {},
   "source": [
    "## Running an Ollama service\n",
    "\n",
    "To execute the code provided in this notebook, you‚Äôll need to have Ollama installed on your local machine and have its LLM hosting service running. To download Ollama, follow the instructions found on this page: https://ollama.com/download. After downloading and installing Ollama, you can start a service by opening a terminal and running the command `ollama serve`.\n",
    "\n",
    "If running on Runpod using the Runpod templates for this Capstone project, then an Ollama service will already be running for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d00219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from llm_agents_from_scratch.logger import enable_console_logging\n",
    "\n",
    "enable_console_logging(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a22f9d4",
   "metadata": {},
   "source": [
    "## Creating an MCPToolProvider for GoodNews MCP Server\n",
    "\n",
    "Unlike the HTTP-based MCP servers, `mcp-goodnews` runs locally as a subprocess\n",
    "and is connected to via the stdio transport. We connect to it using the\n",
    "`stdio_params` parameter on `MCPToolProvider`.\n",
    "\n",
    "Before running the cells below, you'll need to clone the `mcp-goodnews` repo\n",
    "to your local machine:\n",
    "\n",
    "```sh\n",
    "mkdir -p ~/mcp-servers\n",
    "cd ~/mcp-servers\n",
    "git clone https://github.com/VectorInstitute/mcp-goodnews\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0064f14-5f1d-4da7-a6af-f1e5de06e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key: \")\n",
    "os.environ[\"NEWS_API_KEY\"] = getpass.getpass(\"News API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "768aec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from mcp import StdioServerParameters\n",
    "\n",
    "from llm_agents_from_scratch.tools.mcp import MCPToolProvider\n",
    "\n",
    "server_path = Path.home() / \"mcp-servers/mcp-goodnews/src/mcp_goodnews\"\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"uv\",\n",
    "    args=[\"run\", \"--with\", \"mcp\", \"mcp\", \"run\", \"server.py\"],\n",
    "    cwd=server_path,\n",
    "    env={\n",
    "        \"NEWS_API_KEY\": os.environ[\"NEWS_API_KEY\"],\n",
    "        \"COHERE_API_KEY\": os.environ[\"COHERE_API_KEY\"],\n",
    "    },\n",
    ")\n",
    "goodnews_mcp_provider = MCPToolProvider(\n",
    "    name=\"goodnews_mcp\",\n",
    "    stdio_params=server_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbeaa70",
   "metadata": {},
   "source": [
    "## Create our LLM agent\n",
    "\n",
    "We'll now use the `LLMAgentBuilder` class to create an LLM agent equipped with\n",
    "the tools from the GoodNews MCP server. Recall from Chapter 5 that the builder\n",
    "takes care of tool discovery for each of its attached MCP tool providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd4c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_agents_from_scratch import LLMAgentBuilder\n",
    "from llm_agents_from_scratch.llms import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(\n",
    "    model=\"qwen3:14b\",\n",
    ")\n",
    "\n",
    "agent = (\n",
    "    await LLMAgentBuilder()\n",
    "    .with_llm(llm)\n",
    "    .with_mcp_provider(goodnews_mcp_provider)\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0d8afd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcp__goodnews_mcp__fetch_list_of_goodnews:\n",
      "\tFetch a list of headlines and return only top-ranked news based on positivity....\n"
     ]
    }
   ],
   "source": [
    "# Print all tools\n",
    "for tool in agent.tools:\n",
    "    desc = (tool.description or \"\")[:100]\n",
    "    print(f\"{tool.name}:\\n\\t{desc}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "888988d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'category': {'default': 'all',\n",
       "   'enum': ['all', 'science', 'health', 'technology'],\n",
       "   'title': 'Category',\n",
       "   'type': 'string'}},\n",
       " 'title': 'fetch_list_of_goodnewsArguments',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.tools_registry[\n",
    "    \"mcp__goodnews_mcp__fetch_list_of_goodnews\"\n",
    "].parameters_json_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a69a2f4",
   "metadata": {},
   "source": [
    "## A simple task for our agent\n",
    "\n",
    "Now that we have our agent, let's give it a simple task to perform. The GoodNews\n",
    "MCP server exposes a single tool, `fetch_list_of_goodnews`, which accepts an\n",
    "optional `category` parameter. The supported categories are `all`, `science`,\n",
    "`health`, and `technology`. We'll ask our agent to fetch some good news in the\n",
    "health category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01bac4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task\n",
    "from llm_agents_from_scratch.data_structures import Task\n",
    "\n",
    "instruction = (\n",
    "    \"Show me some good news articles in the science category. \"\n",
    "    \"Your final answer must contain ONLY the article titles and URLs from the \"\n",
    "    \"tool results. Do not summarize or describe what you did.\"\n",
    ")\n",
    "task = Task(\n",
    "    instruction=instruction,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f20808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO (llm_agents_fs.LLMAgent) :      üöÄ Starting task: Show me some good news articles in the science category. Your final answer must contain ONLY the article titles and URLs from the too...[TRUNCATED]\n",
      "INFO (llm_agents_fs.TaskHandler) :      ‚öôÔ∏è Processing Step: Show me some good news articles in the science category. Your final answer must contain ONLY the article titles and URLs from the ...[TRUNCATED]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO (llm_agents_fs.TaskHandler) :      üõ†Ô∏è Executing Tool Call: mcp__goodnews_mcp__fetch_list_of_goodnews\n",
      "INFO (llm_agents_fs.TaskHandler) :      ‚úÖ Successful Tool Call: [{'type': 'text', 'text': '{\"articles\": [\\n    {\\n        \"title\": \"Scientists may have found the holy grail of quantum comput...[TRUNCATED]\n",
      "INFO (llm_agents_fs.TaskHandler) :      ‚úÖ Step Result: 1. Scientists may have found the holy grail of quantum computing - ScienceDaily (https://www.sciencedaily.com/releases/2026/02/26022100...[TRUNCATED]\n",
      "INFO (llm_agents_fs.TaskHandler) :      No new step required.\n",
      "INFO (llm_agents_fs.LLMAgent) :      üèÅ Task completed: 1. Scientists may have found the holy grail of quantum computing - ScienceDaily (https://www.sciencedaily.com/releases/2026/02/26022...[TRUNCATED]\n"
     ]
    }
   ],
   "source": [
    "handler = agent.run(task, max_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2217bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Scientists may have found the holy grail of quantum computing - ScienceDaily (https://www.sciencedaily.com/releases/2026/02/260221000252.htm)  \n",
      "2. Amazing study finds that mice perform first aid when their friends are in distress - Earth.com (https://www.earth.com/news/mice-perform-first-aid-cpr-to-unconscious-companions-distress-to-revive-them/)  \n",
      "3. Photographer Stumbles Upon One of the Largest Dinosaur Trackways Ever Recorded - Indian Defence Review (https://indiandefencereview.com/photographer-largest-dinosaur-trackways/)\n"
     ]
    }
   ],
   "source": [
    "result = handler.exception() or handler.result()\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-agents-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
